O que estamos fazendo:
- em aula estamos fazendo um experimento básico de uma LP
- ler o código que o programador digita
- verificar se a sintaxe e tipos estão corretos
- precisamos avaliar o código (rodar) para apresentar um resultado

em LPs precisamos nos preocupar com:
            - análise sintática e 
            - análise semântica


--------------------------------------------------------------------------------------------------------------

análise sintática é constituída pela análise lexica e análise sintática:

      - [anaíse léxica] o Lexer.hs tem a definição da sintaxe (data expr) da linguagem; também define quais são os tipos válidos para a linguagem (data Ty); com data expr e data ty se tem a sintaxe 'abstrata', que é o básico que se precisa para processar a linguagem; mas é preciso  ocódigo fonte (normalmente lido como uma string); para ler esta string do programador, tem-se data Token, que serve para identificar as 'coisas' que o programa (string) contém; data token, portanto, foi criado para identificar as partes da string que compoem o código fonte passado de acordo com a sintaxe da linguagem; o esperado é que o código recebido receba conjuntos de expressões que possam ser validados como tokens da linguagem; se alguma parte da string do código fonte não for convertida para token válido, se tem um erro de símbolo (erro léxico); a passagem da string para a lista de tokens é processada pela função lexer, que está em Lexer.hs; 

                  lexer :: String -> [Token]
                  lexer [] = [] 
                  lexer (c:cs) | isSpace c = lexer cs 
                              | isDigit c = lexNum (c:cs)
                              | isSymb c = lexSymbol (c:cs)
                              | isAlpha c = lexKW (c:cs)
                  lexer _ = error "Lexical error!"

                  A função lexer realiza a leitura de caracter por caracter; o primeiro caso é o caso de fim da recursão, ou seja, string vazia; as outras condições da função trata cada elemento da lista (c:cs -> primeiro : demais elementos da lista); aí, testa cada caracter verificando se é um espaço, se é um digito, se é um símbolo, se é um caracter alfabético; para cada caso, chama uma função específica para o processamento; 
                  
                  - em resumo, a análise sintática pega uma string e traduz para uma lista de tokens; 


      - [análise sintática] que é a segunda parte da parte sintática, recebe uma lista de tokens e vai montar a AST; isso é para verificar se a sequência dos tokens está sendo empregada devidamente; 
      - é um tanto complexo, e, para isso, se usa o happy, que é um gerador de AST, gerador de analisador sintático para haskel; para isso, se tem o arquivo Parser.y que é um mapeamento das informações da LP para que o happy possa gerar a AST; 
      - no Parser.y:
            - %tokentype existe para que se diga o data dos tokens (no nosso caso, é o Token)
            - na seção %token se passa os tokens, fazendo o devido mapamento (relacionamento de elementos)
            - aqui na seção %token, está se tratando da forma como o usuário digita; 

                  --------------------
                  Sintaxe contreta: é o código que o programador escreve; 
                  Sintaxe abstrata: é a representação interna da sintase (no nosso caso é o Expr); 
                  --------------------
            - depois do %%, tem a definição da sintaxe do que o usuário digita
            - trata-se da identificação de cadeias de tokens que são aceitas pela LP
            - ao mesmo tempo que se define a sequencia dos tokens aceitos (coluna à esquerda) já se converte para as Expr correlatas que foram criadas no Lexer.hs; o $ indica a posição, na expressão que o usuaŕio digita (coluna à esquerda) que deve ser usada pelo Expr correspondente; 

            - por fim, parserError é uma expressão simples para tratamento de erro; 
            - toda a vez que o Parser.y for modificado, tem que rodar o happy Parser.y
            - para indicar precedencia de tokens, em parser.y, antes de %token, ter-se ia que dizer %left '+' '-', para dizer que + tem precedência em relação ao -; 

--------------------------------------------------------------------------------------------------------------

análise semântica compreende a verificação de tipos e a avaliação das expressões 

      - typechecker.hs criado faz a avaliação de tipos
            - em typeof se faz a identificação do tipo de uma expressão; 
            - o trabalho do typechecker é filtrar tipos inválidos de acordo com a sintáxe da LP; 
            - idéia é que seja capaz de filtrar os indesejados; 

      - interpreter.hs faz a avaliação
            - trata-se da avaliação de uma expressão passada pelo programador (string); 
            - para que seja possível essa avaliação, é necessário reduzir os problemas a resolução de passo a passo; 
            - isValue é uma expressão criada em interpreter.hs que verifica se se está em uma expressão terminal, ou seja, uma expressão tal que não se possa fazer mais nenhum passo de tratamento; 
            - eval chama step até que não se tenha um isValue; 




      -------------------------

se executar o Lexer.hs e passar lexer "2+3", retorna a lista de tokens da expresão; 

ser der um ghc Main.hs, por exemplo, gera um arquivo binário que é o compilado do main; 
cat example.mylang | ./ Main (depois de compilar o Main com o Main.hs)

echo "2+3" | runghc Main.hs ---- forma de rodar sem precisar rodar previamente




